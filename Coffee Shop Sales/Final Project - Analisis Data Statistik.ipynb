{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qggYw48bpPXk"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import itertools\n","from sklearn.model_selection import train_test_split\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.tsa.stattools import adfuller\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ATgqjw9pi8s"},"outputs":[],"source":["#from google.colab import files\n","#uploaded = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYrO3K-CrpZU"},"outputs":[],"source":["# Load the uploaded CSV file\n","file_path = \"C:/Users/Nabilah/OneDrive - Institut Teknologi Sepuluh Nopember/SEMESTER 7/Coffee Shop Sales.csv\"\n","df = pd.read_csv(file_path)\n","df.set_index('transaction_date', inplace=True)\n","df.index = pd.to_datetime(df.index)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jzf_WwwMrqV_"},"outputs":[],"source":["# Group by store location and transaction date, then sum transaction quantity\n","transaction_sum_by_store = df.groupby(['store_location', df.index])['transaction_qty'].sum()\n","\n","# Display the result\n","transaction_sum_by_store"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"om851Xy1ryRg"},"outputs":[],"source":["# Iterate through each store location and create a line plot\n","for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    plt.figure(figsize=(12, 6))\n","    plt.plot(transaction_sum_by_store[store].index, transaction_sum_by_store[store].values)\n","    plt.xlabel('Transaction Date')\n","    plt.ylabel('Total Transaction Quantity')\n","    plt.title(f'Total Transaction Quantity Over Time for {store}')\n","    plt.grid(True)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUdAWAYksJyM"},"outputs":[],"source":["for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    # Extract the time series for the current store\n","    store_data = transaction_sum_by_store[store]\n","\n","    # Perform ADF test\n","    result = adfuller(store_data)\n","    print(f'\\nADF Test for {store}:')\n","    print('ADF Statistic: %f' % result[0])\n","    print('p-value: %f' % result[1])\n","    print('Critical Values:')\n","    for key, value in result[4].items():\n","        print('\\t%s: %.3f' % (key, value))\n","\n","    # Interpret the results and apply differencing if necessary\n","    if result[1] > 0.05:\n","        print(f\"The time series for {store} is likely non-stationary.\")\n","        store_data_diff = store_data.diff().dropna()  # First-order differencing\n","        result_diff = adfuller(store_data_diff)\n","        print('\\nADF Statistic after differencing: %f' % result_diff[0])\n","        print('p-value after differencing: %f' % result_diff[1])\n","        if result_diff[1] <= 0.05:\n","            print(f\"Reject H0 - Time Series for {store} is stationary after differencing\")\n","        else:\n","            print(f\"Fail to reject H0 - Time Series for {store} is still non-stationary after differencing\")\n","    else:\n","        print(f\"The time series for {store} is likely stationary.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPSrcNfnzin2"},"outputs":[],"source":["for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    store_data = transaction_sum_by_store[store]\n","\n","    if result[1] > 0.05:\n","        store_data = store_data_diff\n","\n","    fig, axes = plt.subplots(1, 2, figsize=(16, 3))\n","    plot_acf(store_data, lags=20, ax=axes[0])\n","    plot_pacf(store_data, lags=20, ax=axes[1])\n","\n","    # Add title with spacing\n","    plt.suptitle(f'ACF and PACF for {store}', y=1.05)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJcOVDUFoDon"},"outputs":[],"source":["#Cari Model Sarima Terbaik Untuk Masing-Masing Store\n","for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    # Extract data for the current store\n","    store_data = transaction_sum_by_store[store]\n","\n","    # Split data into training and testing sets\n","    train_data, test_data = train_test_split(store_data, test_size=30, shuffle=False)\n","\n","    # Define parameter ranges\n","    p = range(0, 4)\n","    d = [1]\n","    q = range(0, 2)\n","    P = range(0, 4)\n","    D = [1]\n","    Q = range(0, 2)\n","    s = [30]\n","\n","    best_aic = float('inf')\n","    best_pdq = None\n","    best_seasonal_pdq = None\n","    best_model = None\n","\n","    for param in itertools.product(p, d, q):\n","        for seasonal_param in itertools.product(P, D, Q, s):\n","          try:\n","              model = SARIMAX(train_data, order=param, seasonal_order=seasonal_param)\n","              results = model.fit()\n","\n","              # Check p-values\n","              if all(pval < 0.05 for pval in results.pvalues):\n","                if results.aic < best_aic:\n","                    best_aic = results.aic\n","                    best_pdq = param\n","                    best_seasonal_pdq = seasonal_param\n","                    best_model = results\n","                    print(f\"Store: {store}, Order: {param}, Seasonal Order: {seasonal_param}, AIC: {results.aic}, p-values: {results.pvalues}\")\n","          except Exception as e:\n","              print(f\"Error for {store}, order {param}, seasonal order {seasonal_param}: {e}\")\n","              continue\n","\n","    if best_model:\n","        print(f\"\\nBest SARIMAX order for {store} with all significant p-values: {best_pdq}x{best_seasonal_pdq}, AIC: {best_aic}\")\n","        print(\"\\nModel Summary:\")\n","        print(best_model.summary())\n","    else:\n","        print(f\"No SARIMAX order found for {store} with all significant p-values.\")"]},{"cell_type":"markdown","metadata":{"id":"7o1iUIBxEcvQ"},"source":["# **ASTORIA**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2xpXzgAJzlTn"},"outputs":[],"source":["for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    if store == \"Astoria\":\n","        # Extract data for Astoria\n","        store_data = transaction_sum_by_store[store]\n","\n","        # Split data into training and testing sets\n","        train_data, test_data = train_test_split(store_data, test_size=30, shuffle=False)\n","\n","        # Model Building and Training\n","        try:\n","            p, d, q = 0, 1, 1  # Non-seasonal\n","            P, D, Q, s = 0, 1, 1, 30  # Seasonal\n","            model = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n","            results = model.fit()\n","            print(f\"\\nSARIMA Model Summary for {store}:\")\n","            print(results.summary())\n","            results.plot_diagnostics(figsize=(15, 12))\n","            plt.show()\n","\n","            # Forecasting\n","            forecast_steps = len(test_data)\n","            forecast = results.get_forecast(steps=forecast_steps)\n","            forecast_mean = forecast.predicted_mean\n","            forecast_conf_int = forecast.conf_int()\n","\n","            # Plot the forecast against the actual values\n","            plt.figure(figsize=(12, 6))\n","            plt.plot(train_data.index, train_data.values, label='Training Data')\n","            plt.plot(test_data.index, test_data.values, label='Actual Values')\n","            plt.plot(forecast_mean.index, forecast_mean.values, label='Forecast')\n","            plt.fill_between(forecast_conf_int.index, forecast_conf_int.iloc[:,0], forecast_conf_int.iloc[:,1], color='k', alpha=.2)\n","            plt.xlabel('Transaction Date')\n","            plt.ylabel('Total Transaction Quantity')\n","            plt.title(f'Forecast vs Actual for {store}')\n","            plt.legend()\n","            plt.grid(True)\n","            plt.show()\n","\n","        except Exception as e:\n","            print(f\"Error fitting SARIMA model for {store}: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gubEoC7F7CSM"},"outputs":[],"source":["# Filter data untuk store \"Astoria\"\n","store_name = \"Astoria\"\n","if store_name in transaction_sum_by_store.index.get_level_values(0).unique():\n","    # Extract the time series for the selected store\n","    store_data = transaction_sum_by_store.loc[store_name]\n","    print(f\"--- Processing data for store: {store_name} ---\")\n","\n","    # Split data into training and testing sets\n","    train_data, test_data = train_test_split(store_data, test_size=0.2, shuffle=False)\n","\n","    # Model Building and Training (using training data)\n","    p, d, q = 0, 1, 1  # non-seasonal\n","    P, D, Q, s = 0, 1, 1, 30  # seasonal\n","    try:\n","        model = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n","        results = model.fit()\n","\n","        # Forecast future values\n","        future_steps = 30  # Number of steps to forecast into the future\n","        future_forecast = results.get_forecast(steps=future_steps)\n","        future_mean = future_forecast.predicted_mean\n","        future_conf_int = future_forecast.conf_int()\n","\n","        # Create future dates for plotting\n","        last_date = store_data.index[-1]\n","        future_dates = pd.date_range(start=last_date + pd.DateOffset(1), periods=future_steps)\n","\n","        # Plot future predictions\n","        plt.figure(figsize=(12, 6))\n","        plt.plot(store_data.index, store_data, label='Historical Data')\n","        plt.plot(future_dates, future_mean, label='Future Forecast')\n","        plt.fill_between(future_dates, future_conf_int.iloc[:, 0], future_conf_int.iloc[:, 1], color='gray', alpha=0.3, label='Confidence Interval')\n","\n","        plt.xlabel('Transaction Date')\n","        plt.ylabel('Total Transaction Quantity')\n","        plt.title(f'Future Predictions for {store_name}')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.show()\n","\n","    except Exception as e:\n","        print(f\"Error processing store {store_name}: {e}\")\n","else:\n","    print(f\"Store {store_name} not found in the data.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AAy7CS2JA4As"},"outputs":[],"source":["def mape(y_true, y_pred):\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true))*100\n","\n","for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    if store == \"Astoria\":\n","        # Extract data for the store\n","        store_data = transaction_sum_by_store[store]\n","        # Split data into training and testing sets\n","        train_data, test_data = train_test_split(store_data, test_size=30, shuffle=False)\n","        # Model Building and Training\n","        try:\n","            p, d, q = 0, 1, 1  # Non-seasonal\n","            P, D, Q, s = 0, 1, 1, 30  # Seasonal\n","            model = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n","            results = model.fit()\n","\n","            # Forecasting\n","            forecast_steps = len(test_data)\n","            forecast = results.get_forecast(steps=forecast_steps)\n","            forecast_mean = forecast.predicted_mean\n","\n","            # Calculate MAPE\n","            store_mape = mape(test_data, forecast_mean)\n","            print(f\"Store: {store}, MAPE: {store_mape}\")\n","\n","        except Exception as e:\n","            print(f\"Error calculating MAPE for {store}: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"21MoNOJnD7Sh"},"source":["# **HELL'S KITCHEN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ga8GBLAQ0gOs"},"outputs":[],"source":["for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    if store == \"Hell's Kitchen\":\n","        # Extract data for Hell's Kitchen\n","        store_data = transaction_sum_by_store[store]\n","        # Split data into training and testing sets\n","        train_data, test_data = train_test_split(store_data, test_size=30, shuffle=False)\n","        # Model Building and Training\n","        try:\n","            p, d, q = 0, 1, 1  # Non-seasonal\n","            P, D, Q, s = 0, 1, 1, 30  # Seasonal\n","            model = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n","            results = model.fit()\n","            print(f\"\\nSARIMA Model Summary for {store}:\")\n","            print(results.summary())\n","            results.plot_diagnostics(figsize=(15, 12))\n","            plt.show()\n","\n","            # Forecasting\n","            forecast_steps = len(test_data)\n","            forecast = results.get_forecast(steps=forecast_steps)\n","            forecast_mean = forecast.predicted_mean\n","            forecast_conf_int = forecast.conf_int()\n","\n","            # Plot the forecast against the actual values\n","            plt.figure(figsize=(12, 6))\n","            plt.plot(train_data.index, train_data.values, label='Training Data')\n","            plt.plot(test_data.index, test_data.values, label='Actual Values')\n","            plt.plot(forecast_mean.index, forecast_mean.values, label='Forecast')\n","            plt.fill_between(forecast_conf_int.index, forecast_conf_int.iloc[:,0], forecast_conf_int.iloc[:,1], color='k', alpha=.2)\n","            plt.xlabel('Transaction Date')\n","            plt.ylabel('Total Transaction Quantity')\n","            plt.title(f'Forecast vs Actual for {store}')\n","            plt.legend()\n","            plt.grid(True)\n","            plt.show()\n","\n","        except Exception as e:\n","            print(f\"Error fitting SARIMA model for {store}: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8VE0uX87ib_"},"outputs":[],"source":["# Filter data untuk store \"Hell's Kitchen\"\n","store_name = \"Hell's Kitchen\"\n","if store_name in transaction_sum_by_store.index.get_level_values(0).unique():\n","    # Extract the time series for the selected store\n","    store_data = transaction_sum_by_store.loc[store_name]\n","    print(f\"--- Processing data for store: {store_name} ---\")\n","\n","    # Split data into training and testing sets\n","    train_data, test_data = train_test_split(store_data, test_size=0.2, shuffle=False)\n","\n","    # Model Building and Training (using training data)\n","    p, d, q = 0, 1, 1  # non-seasonal\n","    P, D, Q, s = 0, 1, 1, 30  # seasonal\n","    try:\n","        model = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n","        results = model.fit()\n","\n","        # Forecast future values\n","        future_steps = 30  # Number of steps to forecast into the future\n","        future_forecast = results.get_forecast(steps=future_steps)\n","        future_mean = future_forecast.predicted_mean\n","        future_conf_int = future_forecast.conf_int()\n","\n","        # Create future dates for plotting\n","        last_date = store_data.index[-1]\n","        future_dates = pd.date_range(start=last_date + pd.DateOffset(1), periods=future_steps)\n","\n","        # Plot future predictions\n","        plt.figure(figsize=(12, 6))\n","        plt.plot(store_data.index, store_data, label='Historical Data')\n","        plt.plot(future_dates, future_mean, label='Future Forecast')\n","        plt.fill_between(future_dates, future_conf_int.iloc[:, 0], future_conf_int.iloc[:, 1], color='gray', alpha=0.3, label='Confidence Interval')\n","\n","        plt.xlabel('Transaction Date')\n","        plt.ylabel('Total Transaction Quantity')\n","        plt.title(f'Future Predictions for {store_name}')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.show()\n","\n","    except Exception as e:\n","        print(f\"Error processing store {store_name}: {e}\")\n","else:\n","    print(f\"Store {store_name} not found in the data.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZuQAWsmhAkDI"},"outputs":[],"source":["def mape(y_true, y_pred):\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    if store == \"Hell's Kitchen\":\n","        # Extract data for the store\n","        store_data = transaction_sum_by_store[store]\n","        # Split data into training and testing sets\n","        train_data, test_data = train_test_split(store_data, test_size=30, shuffle=False)\n","        # Model Building and Training\n","        try:\n","            p, d, q = 0, 1, 1  # Non-seasonal\n","            P, D, Q, s = 0, 1, 1, 30  # Seasonal\n","            model = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n","            results = model.fit()\n","\n","            # Forecasting\n","            forecast_steps = len(test_data)\n","            forecast = results.get_forecast(steps=forecast_steps)\n","            forecast_mean = forecast.predicted_mean\n","\n","            # Calculate MAPE\n","            store_mape = mape(test_data, forecast_mean)\n","            print(f\"Store: {store}, MAPE: {store_mape}\")\n","\n","        except Exception as e:\n","            print(f\"Error calculating MAPE for {store}: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"0CTLnpLtDtuF"},"source":["# **LOWER MANHATTAN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0LgDIcfA04-K"},"outputs":[],"source":["for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    if store == \"Lower Manhattan\":  # Only process data for Lower Manhattan\n","        # Extract data for Lower Manhattan\n","        store_data = transaction_sum_by_store[store]\n","        # Split data into training and testing sets\n","        train_data, test_data = train_test_split(store_data, test_size=30, shuffle=False)\n","        # Model Building and Training\n","        try:\n","            p, d, q = 1, 1, 1  # Non-seasonal\n","            P, D, Q, s = 0, 1, 1, 30  # Seasonal\n","            model = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n","            results = model.fit()\n","            print(f\"\\nSARIMA Model Summary for {store}:\")\n","            print(results.summary())\n","            results.plot_diagnostics(figsize=(15, 12))\n","            plt.show()\n","\n","            # Forecasting\n","            forecast_steps = len(test_data)\n","            forecast = results.get_forecast(steps=forecast_steps)\n","            forecast_mean = forecast.predicted_mean\n","            forecast_conf_int = forecast.conf_int()\n","\n","            # Plot the forecast against the actual values\n","            plt.figure(figsize=(12, 6))\n","            plt.plot(train_data.index, train_data.values, label='Training Data')\n","            plt.plot(test_data.index, test_data.values, label='Actual Values')\n","            plt.plot(forecast_mean.index, forecast_mean.values, label='Forecast')\n","            plt.fill_between(forecast_conf_int.index, forecast_conf_int.iloc[:,0], forecast_conf_int.iloc[:,1], color='k', alpha=.2)\n","            plt.xlabel('Transaction Date')\n","            plt.ylabel('Total Transaction Quantity')\n","            plt.title(f'Forecast vs Actual for {store}')\n","            plt.legend()\n","            plt.grid(True)\n","            plt.show()\n","\n","        except Exception as e:\n","            print(f\"Error fitting SARIMA model for {store}: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojA2XX9b-EnS"},"outputs":[],"source":["# Filter data untuk store \"Lower Manhattan\"\n","store_name = \"Lower Manhattan\"  # Nama store yang ingin diproses\n","if store_name in transaction_sum_by_store.index.get_level_values(0).unique():\n","    # Extract the time series for the selected store\n","    store_data = transaction_sum_by_store.loc[store_name]\n","    print(f\"--- Processing data for store: {store_name} ---\")\n","\n","    # Split data into training and testing sets\n","    train_data, test_data = train_test_split(store_data, test_size=30, shuffle=False)\n","\n","    # Model Building and Training (using training data)\n","    p, d, q = 1, 1, 1  # non-seasonal\n","    P, D, Q, s = 0, 1, 1, 30  # seasonal\n","    try:\n","        model = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n","        results = model.fit()\n","\n","        # Forecast future values\n","        future_steps = 30  # Number of steps to forecast into the future\n","        future_forecast = results.get_forecast(steps=future_steps)\n","        future_mean = future_forecast.predicted_mean\n","        future_conf_int = future_forecast.conf_int()\n","\n","        # Create future dates for plotting\n","        last_date = store_data.index[-1]\n","        future_dates = pd.date_range(start=last_date + pd.DateOffset(1), periods=future_steps)\n","\n","        # Plot future predictions\n","        plt.figure(figsize=(12, 6))\n","        plt.plot(store_data.index, store_data, label='Historical Data')\n","        plt.plot(future_dates, future_mean, label='Future Forecast')\n","        plt.fill_between(future_dates, future_conf_int.iloc[:, 0], future_conf_int.iloc[:, 1], color='gray', alpha=0.5, label='Confidence Interval')\n","\n","        plt.xlabel('Transaction Date')\n","        plt.ylabel('Total Transaction Quantity')\n","        plt.title(f'Future Predictions for {store_name}')\n","        plt.legend()\n","        plt.grid(True)\n","        plt.show()\n","\n","    except Exception as e:\n","        print(f\"Error processing store {store_name}: {e}\")\n","else:\n","    print(f\"Store {store_name} not found in the data.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUmk434G_LJ3"},"outputs":[],"source":["def mape(y_true, y_pred):\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","\n","for store in transaction_sum_by_store.index.get_level_values(0).unique():\n","    if store == \"Lower Manhattan\":  # Only calculate for Lower Manhattan\n","        # Extract data for the store\n","        store_data = transaction_sum_by_store[store]\n","        # Split data into training and testing sets\n","        train_data, test_data = train_test_split(store_data, test_size=30, shuffle=False)\n","        # Model Building and Training\n","        try:\n","            p, d, q = 1, 1, 1  # Non-seasonal\n","            P, D, Q, s = 0, 1, 1, 30  # Seasonal (assuming weekly seasonality)\n","            model = SARIMAX(train_data, order=(p, d, q), seasonal_order=(P, D, Q, s))\n","            results = model.fit()\n","\n","            # Forecasting\n","            forecast_steps = len(test_data)\n","            forecast = results.get_forecast(steps=forecast_steps)\n","            forecast_mean = forecast.predicted_mean\n","\n","            # Calculate MAPE\n","            store_mape = mape(test_data, forecast_mean)\n","            print(f\"Store: {store}, MAPE: {store_mape}\")\n","\n","        except Exception as e:\n","            print(f\"Error calculating MAPE for {store}: {e}\")"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}